---
layout: single
title: "KNN vs Linear Regression"
categories: [project]
tag : [machine learning, Python]
---


# KNN vs Linear Regression


```python
import numpy as np
import matplotlib.pyplot as plt
import sklearn.neighbors as nn
import sklearn.linear_model as lm
```

# Example 1

## Date Generation


```python
p = 2
s = 1
m1 = [1,0]
m0 = [0,1]
```


```python
n = 100
traindata = np.reshape(np.random.normal(size = 2*n*p),(2*n,p))*s + np.concatenate(
    (np.reshape(m1*n, (n,p)),np.reshape(m0*n,(n,p))), axis=0)
Ytrain = np.concatenate(([1]*n, [0]*n))
```


```python
N = 5000
testdata = np.reshape(np.random.normal(size=2*N*p), (2*N ,p))*s + np.concatenate(
    (np.reshape(m1*N, (N, p)),np.reshape(m0*N, (N, p))),axis=0)
Ytest = np.concatenate(([1]*N, [0]*N))
```

## Visualization


```python
# Plot training data
p1 = plt.scatter(traindata[:n, 0],traindata[:n, 1], c="blue", alpha = 0.25)
p0 = plt.scatter(traindata[n:, 0],traindata[n:, 1], c="red", alpha = 0.25)

#highlight centers for the two classes
pm1 = plt.scatter(m1[0], m1[1], marker = "+", s=200, c="blue")
pm0 = plt.scatter(m0[0], m0[1], marker = "+", s=200, c="red")

#add legend
plt.legend((p1,p0), ('class1', "class0"))
plt.show()

```

<figure>
<img src="/assets/images/project/knn/output_8_0.png" width="100" height = "100">
<figcaption>Fig. 1. Train Data</figcaption>
</figure>



## kNN method


```python
myk = [151, 101, 69, 45, 31, 21, 11, 7, 5, 3, 1]
m = len(myk)

train_err_knn = [0]*m
test_err_knn = [0]*m

for j in range(m):
    nbrs = nn.KNeighborsClassifier(n_neighbors = myk[j]).fit(traindata, Ytrain)
    Ytrain_pred = nbrs.predict(traindata)
    train_err_knn[j] = sum(Ytrain != Ytrain_pred)/float(2*N)                            
    Ytest_pred = nbrs.predict(testdata)
    test_err_knn[j] = sum(Ytest != Ytest_pred)/float(2*N)
```

## Least Square Method


```python
regr = lm.LinearRegression()
regr.fit(traindata, Ytrain)
Ytrain_pred_LS = (regr.predict(traindata)>0.5)
Ytest_pred_LS = (regr.predict(testdata)>0.5)
train_err_LS = sum(Ytrain != Ytrain_pred_LS) / float(2*n)
test_err_LS = sum(Ytest != Ytest_pred)/float(2*N)
```

## Bayes Error


```python
Ytest_pred_Bayes = np.dot(2*testdata, np.array(m1) - np.array(m0)) > (sum(np.array(m1)**2) - sum(np.array(m0)**2))
test_err_Bayes = sum(Ytest != Ytest_pred_Bayes) / float(2*N)
```

## Plot the Performance


```python
df = 2*n/np.array(myk)
plt.figure(figsize=(10,6))
pknn_train = plt.scatter(range(m), train_err_knn, color = "blue", marker = "o", alpha = 0.5)
pknn_test = plt.scatter(range(m), test_err_knn, color = "red", marker = "o", alpha = 0.5)

plt.scatter(2, train_err_LS, s = 100, marker = "^", facecolor = "none", edgecolor="blue")
plt.scatter(2, test_err_LS, s = 100, marker = '^', 
            facecolor = 'none', edgecolor = 'red')
pbayes = plt.axhline(y = test_err_Bayes, color = 'green', linestyle = '-')
plt.xticks(range(m), myk, rotation=20)
plt.legend((pknn_train, pknn_test, pbayes), 
           ('train error', 'test error', 'Bayes error'), loc = 'lower left')
plt.show()



```

<figure>
<img src="/assets/images/project/knn/output_16_0.png" width="100" height = "100">
<figcaption>Fig. 2. Final Graph</figcaption>
</figure>

